# üß† Reflection + Memory

## Reflection Loop
El objetivo es que el agente pueda **auto-corregirse** sin que t√∫ intervengas.

**Entrada:**
- tool_name
- user_input (tarea)
- tool_output

**Salida (Pydantic `PeanutReflection`):**
- success: bool
- analysis: str
- peanuts_earned: 0|1
- next_action: retry|finalize
- improved_input: str|null (idealmente JSON)

Si el modelo devuelve texto extra o JSON inv√°lido:
- se intenta extraer el primer objeto JSON,
- si falla, se usa fallback heur√≠stico.

## Peanut Memory (RAG local)
Guarda √©xitos reales:
- task
- tool_name
- tool_args
- tool_result_preview
- embedding

Recupera `top_k=2` ejemplos y los inyecta en el system prompt como:
`ü•ú CONSEJOS DEL PASADO: [...]`

### Embeddings
- Primario: Ollama `/api/embeddings` con `nomic-embed-text`
- Fallback: embedding por hashing determinista (sin dependencias)
